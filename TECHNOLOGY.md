# üõ†Ô∏è TeddyTales - Technology Documentation

## Comprehensive Technology Stack & Integration Guide

This document provides detailed technical information about all technologies used in TeddyTales, how they integrate, and why they were chosen.

---

## üèóÔ∏è Core Architecture

### Monorepo Structure
```
ai-storyteller/
‚îú‚îÄ‚îÄ apps/
‚îÇ   ‚îú‚îÄ‚îÄ ai-storyteller/          # Backend (Raindrop + Hono.js)
‚îÇ   ‚îî‚îÄ‚îÄ ai-storyteller-frontend/ # Frontend (React + Vite)
‚îú‚îÄ‚îÄ db/
‚îÇ   ‚îî‚îÄ‚îÄ story-db/                # Database schemas
‚îú‚îÄ‚îÄ reference/
‚îÇ   ‚îî‚îÄ‚îÄ raindrop-framework/      # Raindrop SDK reference
‚îî‚îÄ‚îÄ README.md
```

**Package Management**: npm workspaces for efficient dependency management

---

## üî∑ Backend Technologies

### 1. Raindrop Platform (Primary Infrastructure)

**Version**: Latest (December 2025)  
**Purpose**: Complete backend infrastructure and deployment platform

#### Components Used

**a) Service Deployment**
```typescript
// raindrop.manifest
service "story-api" {
  visibility = "public"
  domain {
    cname = "ai-storyteller"
  }
}
```
- Deployed at: `ai-storyteller.01kc54r6ayz240zq9k7z4c7yxh.lmapp.run`
- Auto-scaling capability
- HTTPS by default
- Health monitoring included

**b) SmartSQL Database**
```typescript
smartsql "story-db" {}
```
- Managed PostgreSQL instance
- Automatic backups
- Connection pooling
- Type-safe queries via generated types

**Schema:**
```sql
-- stories: Main story metadata
CREATE TABLE stories (
  id SERIAL PRIMARY KEY,
  child_name TEXT NOT NULL,
  age INTEGER NOT NULL,
  theme TEXT,
  english_level TEXT,
  lesson_of_day TEXT,
  created_at TIMESTAMP DEFAULT NOW()
);

-- segments: Story parts with narrative
CREATE TABLE segments (
  id SERIAL PRIMARY KEY,
  story_id INTEGER REFERENCES stories(id),
  segment_order INTEGER NOT NULL,
  segment_text TEXT NOT NULL,
  audio_key TEXT,
  choice_question TEXT,
  is_conclusion BOOLEAN DEFAULT FALSE,
  created_at TIMESTAMP DEFAULT NOW()
);

-- choices: User decision points
CREATE TABLE choices (
  id SERIAL PRIMARY KEY,
  segment_id INTEGER REFERENCES segments(id),
  choice_text TEXT NOT NULL,
  next_segment_id INTEGER,
  created_at TIMESTAMP DEFAULT NOW()
);
```

**c) Bucket Storage**
```typescript
bucket "audio-storage" {}
```
- Audio file metadata storage
- Binary data management
- CDN-ready serving

**d) SmartMemory (Disabled)**
```typescript
smartmemory "story-context" {}
```
- Initially planned for conversation context
- Disabled due to latency issues
- Future optimization planned

#### Development Tools

**Raindrop Code (AI Assistant)**
- Claude-powered development via MCP Server
- Used extensively throughout development
- Generates TypeScript types from manifest
- Provides project scaffolding

**Raindrop CLI**
```bash
# Key commands used
raindrop build init .              # Initialize project
raindrop build generate           # Generate types
raindrop build deploy --start     # Deploy and start
raindrop build status             # Check deployment
raindrop build env set KEY value  # Set secrets
```

#### Environment Variables Management
```typescript
// raindrop.manifest
env "ELEVENLABS_API_KEY" {
  secret = true
}
env "VULTR_INFERENCE_API_KEY" {
  secret = true
}
env "TTS_VOICE_ID" {
  default = "EXAVITQu4vr4xnSDxMaL"
}
```

### 2. Hono.js Web Framework

**Version**: 4.x  
**Why Hono**: Fast, lightweight, TypeScript-first, Cloudflare Workers compatible

```typescript
import { Hono } from 'hono';
import { cors } from 'hono/cors';

const app = new Hono<{ Bindings: Env }>();

// CORS configuration
app.use('*', cors({
  origin: [
    'http://localhost:5173',
    'https://ai-storyteller.01kc54r6ayz240zq9k7z4c7yxh.lmapp.run',
    'https://teddytales.vercel.app',
  ],
  allowMethods: ['GET', 'POST', 'PUT', 'DELETE', 'OPTIONS'],
  credentials: true,
}));

// Request logging middleware
app.use('*', async (c, next) => {
  const start = Date.now();
  console.log(`[${new Date().toISOString()}] ${c.req.method} ${c.req.url}`);
  await next();
  console.log(`Completed in ${Date.now() - start}ms`);
});

export default app;
```

**Features Used:**
- Built-in middleware system
- Type-safe route handlers
- Automatic JSON parsing
- Stream response support (for audio)

### 3. Vultr Serverless Inference

**Endpoint**: `https://api.vultrinference.com/v1/chat/completions`  
**Model**: DeepSeek-R1-Distill-Qwen-32B  
**Purpose**: AI story generation

#### Implementation

```typescript
// vultr_inference.ts
interface VultrInferenceResponse {
  choices: Array<{
    message: {
      content: string;
      role: string;
    };
    index: number;
    finish_reason: string;
  }>;
  model: string;
  usage?: {
    prompt_tokens: number;
    completion_tokens: number;
    total_tokens: number;
  };
}

export async function inference(
  prompt: string,
  apiKey: string
): Promise<VultrInferenceResponse | null> {
  const response = await fetch(
    'https://api.vultrinference.com/v1/chat/completions',
    {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${apiKey}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: 'deepseek-r1-distill-qwen-32b',
        messages: [{ role: 'user', content: prompt }],
      }),
    }
  );
  
  if (!response.ok) {
    console.error('Vultr API Error:', response.statusText);
    return null;
  }
  
  return response.json();
}
```

#### Story Generation Prompt Engineering

```typescript
const storyPrompt = `
Create a personalized children's story with these requirements:

Child's Name: ${child_name}
Age: ${age} years old
Theme: ${theme}
English Level: ${english_level}
Educational Theme: ${lesson_of_day}

Requirements:
1. Use age-appropriate vocabulary for ${age}-year-olds
2. Include ${child_name} as the main character
3. Create an engaging ${theme} adventure
4. End with a question offering 2-3 choices for what happens next
5. Keep segment to 100-150 words
6. Make it educational focusing on ${lesson_of_day}
7. Ensure content is safe and appropriate for children

Format:
[Story text]

[Choice question]
`;

const aiResponse = await inference(storyPrompt, env.VULTR_INFERENCE_API_KEY);
const storyText = aiResponse.choices[0].message.content;
```

**Performance:**
- Average response time: ~10 seconds
- Token usage: ~200-400 tokens per story segment
- Reliability: 99%+ success rate
- Cost: Serverless pricing, pay-per-use

**Why This Model:**
- Excellent creative writing capabilities
- Good understanding of age-appropriate content
- Fast inference time for serverless
- Strong context understanding

### 4. ElevenLabs Text-to-Speech

**API**: `https://api.elevenlabs.io/v1/text-to-speech/{voice_id}`  
**Voice**: Sarah (ID: EXAVITQu4vr4xnSDxMaL)  
**Purpose**: Professional audio narration

#### Implementation

```typescript
// service-integrations.ts
export class ElevenLabsService {
  constructor(
    private apiKey: string,
    private voiceId: string = 'EXAVITQu4vr4xnSDxMaL'
  ) {}

  async textToSpeech(text: string): Promise<ArrayBuffer> {
    const response = await fetch(
      `https://api.elevenlabs.io/v1/text-to-speech/${this.voiceId}`,
      {
        method: 'POST',
        headers: {
          'xi-api-key': this.apiKey,
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          text,
          model_id: 'eleven_monolingual_v1',
          voice_settings: {
            stability: 0.5,
            similarity_boost: 0.75,
          },
        }),
      }
    );

    if (!response.ok) {
      throw new Error(`ElevenLabs API error: ${response.statusText}`);
    }

    return response.arrayBuffer();
  }
}
```

#### Audio Serving

```typescript
// Audio endpoint with proper streaming
app.get('/get-audio/:audioKey', async (c) => {
  const audioKey = c.req.param('audioKey');
  
  // Retrieve from bucket storage
  const audioData = await bucket.get(audioKey);
  
  if (!audioData) {
    return c.json({ error: 'Audio not found' }, 404);
  }

  // Serve with proper headers for streaming
  return c.body(audioData, 200, {
    'Content-Type': 'audio/mpeg',
    'Cache-Control': 'public, max-age=3600',
  });
});
```

**Voice Characteristics:**
- Warm, friendly tone perfect for children
- Clear pronunciation
- Engaging pacing
- Professional quality

**Performance:**
- Generation time: ~5 seconds per segment
- Audio quality: High-quality MP3
- File size: 500KB-700KB per segment
- Streaming: Progressive loading support

---

## üî∂ Frontend Technologies

### 1. React + TypeScript

**React Version**: 18.2.0  
**TypeScript Version**: 5.3.3

**Why This Stack:**
- Industry standard for web applications
- Strong type safety prevents bugs
- Excellent developer experience
- Great ecosystem and community

#### Key Components

```typescript
// App.tsx - Main application component
import { useState, useEffect } from 'react';
import { StoryAPI } from './utils/api';
import StoryCreationForm from './components/StoryCreationForm';
import StoryDisplay from './components/StoryDisplay';

function App() {
  const [currentStory, setCurrentStory] = useState(null);
  const [loading, setLoading] = useState(false);

  const createStory = async (request) => {
    setLoading(true);
    try {
      const story = await StoryAPI.createStory(request);
      setCurrentStory(story);
    } catch (error) {
      console.error('Failed to create story:', error);
    } finally {
      setLoading(false);
    }
  };

  return (
    <div className="app">
      {!currentStory ? (
        <StoryCreationForm onSubmit={createStory} loading={loading} />
      ) : (
        <StoryDisplay story={currentStory} />
      )}
    </div>
  );
}
```

### 2. Vite Build Tool

**Version**: 5.0.12  
**Why Vite**: Lightning-fast HMR, optimized builds, excellent DX

```typescript
// vite.config.ts
import { defineConfig } from 'vite';
import react from '@vitejs/plugin-react';

export default defineConfig({
  plugins: [react()],
  server: {
    port: 5173,
    open: true,
  },
  build: {
    outDir: 'dist',
    sourcemap: true,
  },
});
```

**Benefits:**
- Instant server start
- Hot Module Replacement (HMR) in milliseconds
- Optimized production builds
- Native ESM support

### 3. Tailwind CSS

**Version**: 3.4.1  
**Purpose**: Utility-first styling for rapid UI development

```typescript
// tailwind.config.js
export default {
  content: ['./index.html', './src/**/*.{js,ts,jsx,tsx}'],
  theme: {
    extend: {
      colors: {
        'storybook-cream': '#FEF3C7',
        'storybook-brown': '#78350F',
        'storybook-sage': '#10B981',
        'storybook-sunset': '#F59E0B',
      },
      fontFamily: {
        handwritten: ['Caveat', 'cursive'],
        story: ['Crimson Text', 'serif'],
        ui: ['Quicksand', 'sans-serif'],
      },
    },
  },
  plugins: [require('@tailwindcss/typography')],
};
```

**Design System:**
- Child-friendly color palette
- Responsive breakpoints
- Custom animations
- Typography plugin for story text

### 4. Framer Motion

**Version**: 10.16.16  
**Purpose**: Smooth animations and transitions

```typescript
// LoadingAnimation.tsx
import { motion } from 'framer-motion';

export default function LoadingAnimation() {
  return (
    <motion.div
      animate={{
        scale: [1, 1.2, 1],
        rotate: [0, 360],
      }}
      transition={{
        duration: 2,
        repeat: Infinity,
      }}
    >
      üé≠
    </motion.div>
  );
}
```

**Animations Used:**
- Page transitions
- Button hover effects
- Loading indicators
- Choice selection feedback

### 5. Axios HTTP Client

**Version**: 1.6.5  
**Purpose**: API communication

```typescript
// utils/api.ts
import axios from 'axios';

const api = axios.create({
  baseURL: 'https://ai-storyteller.01kc54r6ayz240zq9k7z4c7yxh.lmapp.run',
  timeout: 30000,
  headers: {
    'Content-Type': 'application/json',
  },
});

// Request interceptor for logging
api.interceptors.request.use((config) => {
  console.log(`API Request: ${config.method?.toUpperCase()} ${config.url}`);
  return config;
});

// Response interceptor for error handling
api.interceptors.response.use(
  (response) => response,
  (error) => {
    console.error('API Error:', error.message);
    throw error;
  }
);

export const StoryAPI = {
  async createStory(request: StoryRequest): Promise<StoryResponse> {
    const { data } = await api.post('/start-story', request);
    return data;
  },
  
  async continueStory(segmentId: number, choice: string): Promise<StoryResponse> {
    const { data } = await api.post('/continue-story', {
      segment_id: segmentId,
      audio_blob: choice,
    });
    return data;
  },
};
```

---

## üî∏ Additional Services

### 1. Pollinations.ai (Image Generation)

**API**: `https://image.pollinations.ai/prompt/{encoded_prompt}`  
**Purpose**: AI-generated story illustrations

```typescript
// utils/api.ts
const IMAGE_API_BASE = 'https://image.pollinations.ai/prompt';

export function generateImageUrl(storyText: string): string {
  const prompt = `Children's book illustration, ${storyText.substring(0, 100)}, 
    warm colors, friendly characters, storybook style`;
  const encoded = encodeURIComponent(prompt);
  return `${IMAGE_API_BASE}/${encoded}?width=800&height=600`;
}
```

**Usage in Components:**
```typescript
// StoryDisplay.tsx
<img 
  src={generateImageUrl(story.segment_text)}
  alt="Story illustration"
  className="rounded-lg shadow-lg"
/>
```

**Benefits:**
- Free, no API key required
- Fast generation
- Consistent style
- Simple URL-based API

### 2. Vercel (Frontend Hosting)

**Purpose**: Production deployment and hosting

```json
// vercel.json
{
  "framework": "vite",
  "buildCommand": "npm run build",
  "outputDirectory": "dist",
  "rewrites": [
    {
      "source": "/(.*)",
      "destination": "/index.html"
    }
  ],
  "headers": [
    {
      "source": "/static/(.*)",
      "headers": [
        {
          "key": "Cache-Control",
          "value": "public, max-age=31536000, immutable"
        }
      ]
    }
  ]
}
```

**Deployment:**
```bash
npx vercel --prod
# Deployed to: https://teddytales.vercel.app/
```

**Features Used:**
- Automatic HTTPS
- Global CDN
- Git integration
- Zero-config deployment
- Edge network for low latency

---

## üîó Integration Patterns

### API Communication Flow

```typescript
// Frontend ‚Üí Backend ‚Üí AI Services

// 1. Frontend initiates request
const response = await StoryAPI.createStory({
  child_name: 'Emma',
  age: 6,
  theme: 'adventure',
});

// 2. Backend receives and orchestrates
app.post('/start-story', async (c) => {
  const request = await c.req.json();
  
  // 2a. Generate story via Vultr
  const aiResponse = await inference(prompt, env.VULTR_INFERENCE_API_KEY);
  const storyText = aiResponse.choices[0].message.content;
  
  // 2b. Create audio via ElevenLabs
  const ttsService = new ElevenLabsService(env.ELEVENLABS_API_KEY);
  const audioBuffer = await ttsService.textToSpeech(storyText);
  
  // 2c. Store in database
  const storyId = await db.insertStory(request);
  const segmentId = await db.insertSegment(storyId, storyText);
  
  // 2d. Save audio to bucket
  await bucket.put(`story-${storyId}-segment-${segmentId}.mp3`, audioBuffer);
  
  // 3. Return to frontend
  return c.json({
    story_id: storyId,
    segment_id: segmentId,
    segment_text: storyText,
    audio_url: `/get-audio/story-${storyId}-segment-${segmentId}.mp3`,
  });
});
```

### Error Handling Strategy

```typescript
// Comprehensive error handling across the stack

// Backend
try {
  const aiResponse = await inference(prompt, apiKey);
  if (!aiResponse) {
    throw new Error('AI service unavailable');
  }
} catch (error) {
  console.error('Story generation failed:', error);
  return c.json({ 
    error: 'Failed to generate story. Please try again.' 
  }, 500);
}

// Frontend
try {
  const story = await StoryAPI.createStory(request);
  setCurrentStory(story);
} catch (error) {
  showErrorMessage('Unable to create story. Check your connection.');
  console.error(error);
}
```

---

## üìä Performance Optimizations

### Backend Optimizations

1. **Connection Pooling**: Database connections reused
2. **Audio Caching**: 1-hour cache on audio files
3. **Lazy Loading**: Services initialized on demand
4. **Async Operations**: Non-blocking I/O throughout

### Frontend Optimizations

1. **Code Splitting**: Vite automatically splits bundles
2. **Lazy Image Loading**: Images load as needed
3. **Audio Preloading**: Next segment audio fetched early
4. **Memoization**: Expensive computations cached with `useMemo`

```typescript
import { useMemo } from 'react';

const imageUrl = useMemo(
  () => generateImageUrl(story.segment_text),
  [story.segment_text]
);
```

---

## üîí Security Considerations

### API Key Management
- All secrets stored in Raindrop environment variables
- Never exposed in frontend code
- Accessed only in backend

### CORS Configuration
- Explicit origin allowlist
- Credentials support for future features
- Method restrictions

### Input Validation
```typescript
// Backend validation
const validateStoryRequest = (data: any): data is StoryRequest => {
  return (
    typeof data.child_name === 'string' &&
    data.child_name.length > 0 &&
    typeof data.age === 'number' &&
    data.age >= 3 &&
    data.age <= 12
  );
};
```

---

## üß™ Testing Approach

### Backend Testing
```typescript
// index.test.ts
describe('Story API', () => {
  it('creates a new story', async () => {
    const response = await app.request('/start-story', {
      method: 'POST',
      body: JSON.stringify({
        child_name: 'Test Child',
        age: 5,
        theme: 'adventure',
      }),
    });
    
    expect(response.status).toBe(200);
    const data = await response.json();
    expect(data.story_id).toBeDefined();
  });
});
```

### Manual Testing Checklist
- ‚úÖ Story creation with various inputs
- ‚úÖ Audio playback in different browsers
- ‚úÖ Image loading and display
- ‚úÖ Choice selection and continuation
- ‚úÖ Error handling for network failures
- ‚úÖ Mobile responsiveness

---

## üìà Monitoring & Logging

### Backend Logging
```typescript
// Structured logging with timestamps
console.log(`[${new Date().toISOString()}] Story created: ${storyId}`);
console.log(`Vultr inference time: ${inferenceTime}ms`);
console.log(`ElevenLabs TTS time: ${ttsTime}ms`);
```

### Health Endpoints
```typescript
app.get('/health/services', async (c) => {
  return c.json({
    status: 'healthy',
    services: {
      raindrop_services: {
        smartsql: 'Available',
        bucket_storage: 'Available',
      },
      external_integrations: {
        elevenlabs_tts: {
          configured: !!env.ELEVENLABS_API_KEY,
        },
        vultr_inference: {
          configured: !!env.VULTR_INFERENCE_API_KEY,
        },
      },
    },
  });
});
```

---

## üöÄ Deployment Process

### Backend Deployment (Raindrop)
```bash
# 1. Validate manifest
raindrop build validate

# 2. Generate types
raindrop build generate

# 3. Deploy and start
raindrop build deploy --start

# 4. Check status
raindrop build status

# 5. View logs
raindrop build logs
```

### Frontend Deployment (Vercel)
```bash
# 1. Build locally (optional)
npm run build

# 2. Deploy to production
npx vercel --prod

# Automatic deployment on git push to main
```

---

## üìö Development Resources

### Documentation Links
- [Raindrop Platform Docs](https://docs.raindrop.ai)
- [Vultr Inference API](https://docs.vultr.com/inference)
- [ElevenLabs API Docs](https://docs.elevenlabs.io)
- [Hono.js Documentation](https://hono.dev)
- [React Documentation](https://react.dev)

### Key npm Packages
```json
{
  "dependencies": {
    "hono": "^4.0.0",
    "@liquidmetal-ai/raindrop": "latest",
    "react": "^18.2.0",
    "axios": "^1.6.5",
    "framer-motion": "^10.16.16"
  }
}
```

---

## üéì Lessons Learned

### What Worked Well
1. Raindrop's one-command deployment saved hours
2. Vultr Serverless Inference was immediately accessible
3. ElevenLabs TTS quality exceeded expectations
4. TypeScript prevented numerous runtime errors
5. Vite's HMR made frontend development fast

### What We'd Do Differently
1. Start with simpler SmartMemory implementation
2. Implement caching earlier in development
3. Add comprehensive error tracking from day one
4. Create more reusable components
5. Write tests alongside features

### Future Technical Improvements
1. Implement WebSocket for real-time story generation
2. Add Redis caching layer for frequently accessed stories
3. Optimize Vultr prompts for faster inference
4. Implement progressive web app (PWA) features
5. Add analytics for usage patterns

---

This comprehensive technology documentation provides complete visibility into how TeddyTales was built, showcasing the deep integration of Raindrop, Vultr, and ElevenLabs services.
